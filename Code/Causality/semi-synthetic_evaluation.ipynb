{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-06T11:06:56.882680200Z",
     "start_time": "2023-12-06T11:06:56.173043900Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from interpret.glassbox import ExplainableBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path)\n",
    "df.drop(columns=['user_id','label'], inplace=True)\n",
    "# log transformation\n",
    "df[[\"status_count\", \"followers_count\", \"friend_count\"]] = df[\n",
    "        [\"status_count\", \"followers_count\", \"friend_count\"]].applymap(lambda x: x + 1)\n",
    "df[[\"status_count\", \"followers_count\", \"friend_count\"]] = df[\n",
    "        [\"status_count\", \"followers_count\", \"friend_count\"]].apply(np.log)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T11:07:02.448587700Z",
     "start_time": "2023-12-06T11:07:02.272316700Z"
    }
   },
   "id": "749d5cd72e8bb351"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "col_means = [df[col].mean() for col in df.columns]\n",
    "def generate_y(df, noise=0.7, seed=32):\n",
    "    \"\"\"\n",
    "    Generate y  \n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    beta = np.random.uniform(-1, 1, size=df.shape[1]) /1000\n",
    "    \n",
    "    df_y = df.copy()\n",
    "    for i, col in enumerate(df.columns):\n",
    "        df_y[col] = df_y[col] * beta[i]\n",
    "        df_y[col] = np.max((df_y[col].mean() - df_y[col]), 0)\n",
    "    y = np.sum(df_y, axis=1) + np.random.normal(0, noise, size=df.shape[0])\n",
    "    #  \n",
    "    y = 1 / (1 + np.exp(-y)) # sigmoid\n",
    "    y = y.rename('y', inplace=True)\n",
    "    return y\n",
    "\n",
    "def test_counterfactuals(df, model, cf_per_obs=20, seed=32):\n",
    "    \"\"\"\n",
    "    Generate counterfactuals for a given model\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    df = df.copy()\n",
    "    if 'y' in df.columns:\n",
    "        df.drop(columns=['y'], inplace=True)\n",
    "    names_treatments = ['verified', 'register_time', 'status_count', 'followers_count',\n",
    "       'friend_count']\n",
    "    df_treatments = df[names_treatments]\n",
    "    df.drop(columns=names_treatments, inplace=True)\n",
    "    names_confounders = df.columns.to_list()\n",
    "    # repeat each observation cf_per_obs times\n",
    "    df = df.loc[df.index.repeat(cf_per_obs)].reset_index(drop=True)\n",
    "    # add random treatment values to dataset in front of each observation\n",
    "\n",
    "    # samples from marginal columnwise joint distribution:\n",
    "    df_treatments = df_treatments.sample(n=df.shape[0], replace=True).reset_index(drop=True)\n",
    "    # concat with confounders\n",
    "    df = pd.concat([df_treatments, df[names_confounders]], axis=1)\n",
    "    \n",
    "    # generate y\n",
    "    y = generate_y(df, seed=seed)\n",
    "    y_hat = model.predict(df)\n",
    "    # calculate rmse\n",
    "    rmse = mean_squared_error(y, y_hat, squared=False)\n",
    "    return rmse\n",
    "\n",
    "def test_factual(df_real, model, seed=32):\n",
    "    y = generate_y(df_real, seed=seed)\n",
    "    y_hat = model.predict(df_real)\n",
    "    # calculate rmse\n",
    "    rmse = mean_squared_error(y, y_hat, squared=False)\n",
    "    return rmse"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T11:07:26.398601500Z",
     "start_time": "2023-12-06T11:07:26.365322700Z"
    }
   },
   "id": "af7b2019808d7587"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15960, 69)\n",
      "(3990, 69)\n"
     ]
    }
   ],
   "source": [
    "seed = 24\n",
    "\n",
    "df_train = df.sample(frac=0.8, random_state=seed) \n",
    "print(df_train.shape)\n",
    "df_test = df.drop(df_train.index).reset_index(drop=True)\n",
    "print(df_test.shape)\n",
    "df_train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "y_train = generate_y(df_train, seed=seed)\n",
    "results = {}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T11:07:30.113854200Z",
     "start_time": "2023-12-06T11:07:30.028065200Z"
    }
   },
   "id": "7c17d8babfc3b0e0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## EBM\n",
    "from interpret.glassbox import ExplainableBoostingRegressor\n",
    "print(seed)\n",
    "# train\n",
    "f_types = [\"nominal\"]\n",
    "f_types.extend([\"continuous\"] * 68)\n",
    "ebm = ExplainableBoostingRegressor(feature_types=f_types, learning_rate=0.01, max_bins= 512, min_samples_leaf= 3, n_jobs=1)\n",
    "ebm.fit(df_train, y_train)\n",
    "# test\n",
    "rmse = test_counterfactuals(df_test, ebm, cf_per_obs=20, seed=seed)\n",
    "df_real = df_test.copy()\n",
    "rmse_real = test_factual(df_real, ebm, seed=seed)\n",
    "print(\"Counterfactual\", rmse, \"Real\", rmse_real)\n",
    "results[\"EBM_counterfactual\"] = rmse\n",
    "results[\"EBM_real\"] = rmse_real"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "52552c0e499709d4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "from sklearn import linear_model\n",
    "print(seed)\n",
    "# train\n",
    "lr = linear_model.LinearRegression()\n",
    "lr.fit(df_train, y_train)\n",
    "# test\n",
    "rmse = test_counterfactuals(df_test, lr, cf_per_obs=20, seed=seed)\n",
    "df_real = df_test.copy()\n",
    "rmse_real = test_factual(df_real, lr, seed=seed)\n",
    "print(\"Counterfactual\", rmse, \"Real\", rmse_real)\n",
    "results[\"LR_counterfactual\"] = rmse\n",
    "results[\"LR_real\"] = rmse_real"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8e6794da55e1d1fa"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ExNN \n",
    "from exnn import ExNN\n",
    "import tensorflow as tf\n",
    "print(seed)\n",
    "# prepare meta info\n",
    "f_types = [\"nominal\"]\n",
    "f_types.extend([\"continuous\"] * 68)\n",
    "meta_info = {f_name: {\"type\": f_type} for f_name, f_type in zip (df_train.columns, f_types)}\n",
    "meta_info[\"y\"] = {\"type\": \"target\"}\n",
    "\n",
    "# fit model\n",
    "exnn = ExNN(meta_info=meta_info,\n",
    "               subnet_num=10,\n",
    "               subnet_arch=[10, 6],\n",
    "               task_type=\"Regression\",\n",
    "               activation_func=tf.tanh,\n",
    "               batch_size=min(1000, int(df_train.to_numpy().shape[0] * 0.2)),\n",
    "               training_epochs=10000,\n",
    "               lr_bp=0.001,\n",
    "               lr_cl=0.1,\n",
    "               beta_threshold=0.05,\n",
    "               tuning_epochs=100,\n",
    "               l1_proj=0.0001,\n",
    "               l1_subnet=0.00316,\n",
    "               l2_smooth=10**(-6),\n",
    "               verbose=True,\n",
    "               val_ratio=0.2,\n",
    "               early_stop_thres=500)\n",
    "\n",
    "exnn.fit(df_train.to_numpy(), y_train.to_numpy())\n",
    "# test\n",
    "rmse = test_counterfactuals(df_test, exnn, cf_per_obs=20, seed=seed)\n",
    "df_real = df_test.copy()\n",
    "rmse_real = test_factual(df_real, exnn, seed=seed)\n",
    "print(\"Counterfactual\", rmse, \"Real\", rmse_real)    \n",
    "results[\"ExNN_counterfactual\"] = rmse\n",
    "results[\"ExNN_real\"] = rmse_real"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a8fb8483c70983ba"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# NAM\n",
    "from nam.wrapper import NAMRegressor\n",
    "print(seed)\n",
    "random_state = 0\n",
    "nam = NAMRegressor(\n",
    "            num_epochs=10,\n",
    "            num_learners=1,\n",
    "            metric='mse',\n",
    "            early_stop_mode='min',\n",
    "            monitor_loss=False,\n",
    "            n_jobs=1,\n",
    "            random_state=random_state\n",
    "        )\n",
    "nam.fit(df_train, y_train)\n",
    "# test\n",
    "rmse = test_counterfactuals(df_test, nam, cf_per_obs=20, seed=seed)\n",
    "df_real = df_test.copy()\n",
    "rmse_real = test_factual(df_real, nam, seed=seed)\n",
    "print(\"Counterfactual\", rmse, \"Real\", rmse_real)\n",
    "results[\"NAM_counterfactual\"] = rmse\n",
    "results[\"NAM_real\"] = rmse_real"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d807735a6008102"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "{'EBM_counterfactual': 0.11233528790841289,\n 'EBM_real': 0.11117099244009716,\n 'LR_counterfactual': 0.11252664487127256,\n 'LR_real': 0.11156787661982835,\n 'ExNN_counterfactual': 0.11235420006229978,\n 'ExNN_real': 0.11125867399460311,\n 'NAM_counterfactual': 0.12403880478786627,\n 'NAM_real': 0.1198183649542339}"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "83cf81937ad481c5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
